{
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "#installing necessary library \r\n",
                "!pip install -q transformers\r\n",
                "!pip install transformers\r\n",
                "!pip install datasets\r\n",
                "import soundfile as sf\r\n",
                "import torch\r\n",
                "from datasets import load_dataset\r\n",
                "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "source": [
                "# defining model and processory \r\n",
                "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\r\n",
                "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
                        "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "#calling librispeech dataset\r\n",
                "librispeech_samples_ds = load_dataset(\"patrickvonplaten/librispeech_asr_dummy\", \"clean\", split=\"validation\")"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "Reusing dataset librispeech_asr (C:\\Users\\prash\\.cache\\huggingface\\datasets\\librispeech_asr\\clean\\2.1.0\\468ec03677f46a8714ac6b5b64dba02d246a228d92cbbad7f3dc190fa039eab1)\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "source": [
                "#taking random dataset for evaluating \r\n",
                "audio_input, sample_rate = sf.read(librispeech_samples_ds[10][\"file\"])\r\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "source": [
                "input_values = processor(audio_input, sampling_rate=sample_rate, return_tensors=\"pt\").input_values"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "source": [
                "# retrieve logits & take argmax\r\n",
                "logits = model(input_values).logits\r\n",
                "predicted_ids = torch.argmax(logits, dim=-1)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "source": [
                "#generating output \r\n",
                "transcription = processor.decode(predicted_ids[0])\r\n",
                "print(transcription)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "NEAR THE FIRE AND THE ORNAMENTS FRED BROUGHT HOME FROM INDIA ON THE MANTELBOARD\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "source": [
                "target_transcription = \"NEAR THE FIRE AND THE ORNAMENTS FRED BROUGHT HOME FROM INDIA ON THE MANTELBOARD\""
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "source": [
                "with processor.as_target_processor():\r\n",
                "  labels = processor(target_transcription, return_tensors=\"pt\").input_ids"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "source": [
                "#comparing with loss with respect to audio \r\n",
                "loss = model(input_values, labels=labels).loss\r\n",
                "loss.backward()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "source": [
                "print(loss)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "tensor(50.5512, grad_fn=<SumBackward0>)\n"
                    ]
                }
            ],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.8.3",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.8.3 64-bit ('base': conda)"
        },
        "interpreter": {
            "hash": "cbcdce6a926c612543ae8aba0643a88349cf2a8bb8d86298bcef1d1eb04f3dcc"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}